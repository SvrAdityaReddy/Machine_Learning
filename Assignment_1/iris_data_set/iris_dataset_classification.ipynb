{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'target_names', 'DESCR', 'feature_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.target) #gives a detailed descriptipon of the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(iris['data'])\n",
    "# print(data)\n",
    "data_with_labels=np.insert(data, 0, values=iris['target'], axis=1) # first element is the class label\n",
    "# print(data_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Test and Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set=train_test_split(data_with_labels,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_set[:,(3,4)] # taking feature petal length and petal width\n",
    "# Y=(train_set[:,0]==2).astype(np.int) # to map true and false to 1 and 0 respectively\n",
    "# print(X)\n",
    "# print(Y)\n",
    "test_data=test_set[:,(3,4)] # taking feature petal length and petal width\n",
    "train_labels1=(train_set[:,0]==0).astype(np.int)\n",
    "train_labels2=(train_set[:,0]==1).astype(np.int)\n",
    "train_labels3=(train_set[:,0]==2).astype(np.int)\n",
    "# print(len(X))\n",
    "# print(len(train_labels1))\n",
    "test_labels1=(test_set[:,0]==0).astype(np.int)\n",
    "test_labels2=(test_set[:,0]==1).astype(np.int)\n",
    "test_labels3=(test_set[:,0]==2).astype(np.int)\n",
    "# print(test_labels2)\n",
    "# print(test_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y=(Y==2).astype(np.int) # to map true and false to 1 and 0 respectively\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training time - Nearest Neighours is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels1=[]\n",
    "predicted_labels2=[]\n",
    "predicted_labels3=[]\n",
    "for i in range(len(test_data)):\n",
    "    # euclidean distance\n",
    "    minimum_distance=((np.dot(test_data[i],test_data[i]))-2*(np.dot(test_data[i],X[0]))+(np.dot(X[0],X[0])))**0.5\n",
    "    closest_neighbour1=train_labels1[0]\n",
    "    closest_neighbour2=train_labels2[0]\n",
    "    closest_neighbour3=train_labels3[0]\n",
    "    for j in range(1,len(X)):\n",
    "        # euclidean distance\n",
    "        distance=((np.dot(test_data[i],test_data[i]))-2*(np.dot(test_data[i],X[j]))+(np.dot(X[j],X[j])))**0.5\n",
    "        if(distance < minimum_distance):\n",
    "            minimum_distance=distance\n",
    "            closest_neighbour1=train_labels1[j]\n",
    "            closest_neighbour2=train_labels2[j]\n",
    "            closest_neighbour3=train_labels3[j]\n",
    "    predicted_labels1.append(closest_neighbour1)\n",
    "    predicted_labels2.append(closest_neighbour2)\n",
    "    predicted_labels3.append(closest_neighbour3)\n",
    "# print(predicted_labels1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score - Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Iris-Setosa: 1.0\n",
      "Accuracy for Iris-Versicolour: 1.0\n",
      "Accuracy for Iris-Verginica: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Iris-Setosa: \"+str(accuracy_score(test_labels1,predicted_labels1)))\n",
    "print(\"Accuracy for Iris-Versicolour: \"+str(accuracy_score(test_labels2,predicted_labels2)))\n",
    "print(\"Accuracy for Iris-Verginica: \"+str(accuracy_score(test_labels3,predicted_labels3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data is fitted to a Gaussian\n",
    "def probability(mean, std, x):\n",
    "    exponential=np.exp(-1*(x-mean)**2/(2*(std**2)))\n",
    "    return ((1/(std*((22/7.0)**0.5)))*(exponential))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Gausian\n",
    "def gaussian_parameters(X):\n",
    "    mean=np.mean(X,axis=0)\n",
    "    std=np.std(X,axis=0)\n",
    "    return (mean,std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time for Iris-Setosa: 0.00040912628173828125\n",
      "Training time for Iris-Versicolour: 0.00034618377685546875\n",
      "Training time for Iris-Verginica: 0.00032019615173339844\n"
     ]
    }
   ],
   "source": [
    "number_of_classes=len(np.unique(iris.target))\n",
    "train_labels=np.concatenate(([train_labels1], [train_labels2], [train_labels3]), axis=0)\n",
    "# print(test_labels)\n",
    "predicted_labels=[]\n",
    "totalTrainingTime=[]\n",
    "for i in range(number_of_classes):\n",
    "    data_class1=[X[j] for j in range(len(train_labels[i])) if train_labels[i][j]==1] # class1 refers to data corresponding to flower Iris-Virginica\n",
    "    data_class2=[X[j] for j in range(len(train_labels[i])) if train_labels[i][j]==0] # class2 refers to data does not corresponds to flower Iris-Virginica  \n",
    "#     print(data_class1)\n",
    "    start_time = time.time()\n",
    "    (mean_class1,std_class1)=gaussian_parameters(data_class1) # get each features gaussian parameters if their class is class1\n",
    "    (mean_class2,std_class2)=gaussian_parameters(data_class2) # get each features gaussian parameters if their class is class2\n",
    "    end_time = time.time()\n",
    "    totalTrainingTime.append(end_time-start_time)\n",
    "#   print(mean_class1,std_class1)\n",
    "#   print(mean_class2,std_class2)\n",
    "    total_class1=0\n",
    "    for j in range(len(train_labels[i])):\n",
    "        if(train_labels[i][j]==1):\n",
    "            total_class1=total_class1+1\n",
    "    class1_probability=float(total_class1)/len(train_labels[i])\n",
    "    class2_probability=1-class1_probability\n",
    "    class_predicted_labels=[]\n",
    "    for j in range(len(test_data)):\n",
    "        probability_class1=1\n",
    "        probability_class2=1\n",
    "        for k in range(len(test_data[j])):\n",
    "            probability_class1=probability_class1*probability(mean_class1[k],std_class1[k],test_data[j][k])\n",
    "            probability_class2=probability_class2*probability(mean_class2[k],std_class2[k],test_data[j][k])\n",
    "        probability_class1=probability_class1*class1_probability\n",
    "        probability_class2=probability_class2*class2_probability\n",
    "    #     print(probability_class1,probability_class2)\n",
    "        if(probability_class1>probability_class2):\n",
    "            class_predicted_labels.append(1)\n",
    "        else:\n",
    "            class_predicted_labels.append(0)\n",
    "    predicted_labels.append(class_predicted_labels)\n",
    "print(\"Training time for Iris-Setosa: \"+str(totalTrainingTime[0]))\n",
    "print(\"Training time for Iris-Versicolour: \"+str(totalTrainingTime[1]))\n",
    "print(\"Training time for Iris-Verginica: \"+str(totalTrainingTime[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Iris-Setosa: 1.0\n",
      "Accuracy for Iris-Versicolour: 1.0\n",
      "Accuracy for Iris-Verginica: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Iris-Setosa: \"+str(accuracy_score(test_labels1,predicted_labels[0])))\n",
    "print(\"Accuracy for Iris-Versicolour: \"+str(accuracy_score(test_labels2,predicted_labels[1])))\n",
    "print(\"Accuracy for Iris-Verginica: \"+str(accuracy_score(test_labels3,predicted_labels[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of features of test data and insert value \"1\" as first feature in every data point of test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=np.copy(X)\n",
    "X_data=np.insert(X_data, 0, values=[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-1*z))\n",
    "def gradient_descent_logistic_regression(X_data,Y,learning_rate,number_iterations):\n",
    "    theta=np.zeros(X_data.shape[1])\n",
    "    for i in range(number_iterations):\n",
    "        z=np.dot(X_data,theta)\n",
    "#         print(z)\n",
    "        p=sigmoid(z)\n",
    "        gradient=np.dot(X_data.T, (p - Y)) / Y.size\n",
    "#         print(theta)\n",
    "#         print(gradient)\n",
    "        theta=theta-learning_rate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time - Logistic Regression (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time for Iris-Setosa: 0.04112100601196289\n",
      "Training time for Iris-Versicolour: 0.05531501770019531\n",
      "Training time for Iris-Verginica: 0.03831601142883301\n"
     ]
    }
   ],
   "source": [
    "# print(X_data.shape)\n",
    "learning_rate=0.1\n",
    "number_iterations=3000\n",
    "start_time = time.time()\n",
    "theta1=gradient_descent_logistic_regression(X_data,train_labels1,learning_rate,number_iterations)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Setosa: \"+str(training_time))\n",
    "\n",
    "start_time = time.time()\n",
    "theta2=gradient_descent_logistic_regression(X_data,train_labels2,learning_rate,number_iterations)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Versicolour: \"+str(training_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "theta3=gradient_descent_logistic_regression(X_data,train_labels3,learning_rate,number_iterations)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Verginica: \"+str(training_time))\n",
    "# print(theta1)\n",
    "# print(theta2)\n",
    "# print(theta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_new=np.copy(test_data)\n",
    "test_data_new=np.insert(test_data_new, 0, values=[1], axis=1);\n",
    "predicted_labels1=[]\n",
    "predicted_labels2=[]\n",
    "predicted_labels3=[]\n",
    "for i in range(len(test_data_new)):\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta1))>0.5):\n",
    "        predicted_labels1.append(1)\n",
    "    else:\n",
    "        predicted_labels1.append(0)\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta2))>0.5):\n",
    "        predicted_labels2.append(1)\n",
    "    else:\n",
    "        predicted_labels2.append(0)\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta3))>0.5):\n",
    "        predicted_labels3.append(1)\n",
    "    else:\n",
    "        predicted_labels3.append(0)\n",
    "# print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score - Logistic Regression (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Iris-Setosa: 1.0\n",
      "Accuracy for Iris-Versicolour: 0.6888888888888889\n",
      "Accuracy for Iris-Verginica: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Iris-Setosa: \"+str(accuracy_score(test_labels1,predicted_labels1)))\n",
    "print(\"Accuracy for Iris-Versicolour: \"+str(accuracy_score(test_labels2,predicted_labels2)))\n",
    "print(\"Accuracy for Iris-Verginica: \"+str(accuracy_score(test_labels3,predicted_labels3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_logistic_regression(X_data,Y,number_iterations):\n",
    "    theta=np.zeros(X_data.shape[1])\n",
    "    for i in range(number_iterations):\n",
    "        z=np.dot(X_data,theta)\n",
    "        p=sigmoid(z)\n",
    "#         print(p.size)\n",
    "        gradient=np.dot(X_data.T, (p - Y)) / Y.size\n",
    "        column=(np.ones(p.size)).T\n",
    "        prob_product = np.dot(p,column-p)\n",
    "        learning_rate=np.linalg.inv(np.dot(prob_product,np.dot(X_data.T,X_data)/ Y.size))\n",
    "#         print(theta)\n",
    "#         print(gradient)\n",
    "        theta=theta-np.dot(learning_rate,gradient)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time - Logistic Regression (Newton's Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time for Iris-Setosa: 0.18096613883972168\n",
      "Training time for Iris-Versicolour: 0.16084694862365723\n",
      "Training time for Iris-Verginica: 0.16295099258422852\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "theta1=newton_method_logistic_regression(X_data,train_labels1,number_iterations)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Setosa: \"+str(training_time))\n",
    "\n",
    "start_time = time.time()\n",
    "theta2=newton_method_logistic_regression(X_data,train_labels2,number_iterations)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Versicolour: \"+str(training_time))\n",
    "\n",
    "start_time = time.time()\n",
    "theta3=newton_method_logistic_regression(X_data,train_labels3,number_iterations)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Verginica: \"+str(training_time))\n",
    "\n",
    "# print(theta1)\n",
    "# print(theta2)\n",
    "# print(theta3)\n",
    "# theta=newton_method_logistic_regression(X_data,Y,number_iterations)\n",
    "# print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels1=[]\n",
    "predicted_labels2=[]\n",
    "predicted_labels3=[]\n",
    "for i in range(len(test_data_new)):\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta1))>0.5):\n",
    "        predicted_labels1.append(1)\n",
    "    else:\n",
    "        predicted_labels1.append(0)\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta2))>0.5):\n",
    "        predicted_labels2.append(1)\n",
    "    else:\n",
    "        predicted_labels2.append(0)\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta3))>0.5):\n",
    "        predicted_labels3.append(1)\n",
    "    else:\n",
    "        predicted_labels3.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score - Logistic Regression (Newton's method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Iris-Setosa: 1.0\n",
      "Accuracy for Iris-Versicolour: 0.7111111111111111\n",
      "Accuracy for Iris-Verginica: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Iris-Setosa: \"+str(accuracy_score(test_labels1,predicted_labels1)))\n",
    "print(\"Accuracy for Iris-Versicolour: \"+str(accuracy_score(test_labels2,predicted_labels2)))\n",
    "print(\"Accuracy for Iris-Verginica: \"+str(accuracy_score(test_labels3,predicted_labels3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (Library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time - Logistic Regression (Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression=LogisticRegression()\n",
    "start_time = time.time()\n",
    "logistic_regression.fit(X,train_labels1)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Setosa: \"+str(training_time))\n",
    "predicted_labels1=logistic_regression.predict(test_data) # prediction of labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "logistic_regression.fit(X,train_labels2)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Versicolour: \"+str(training_time))\n",
    "predicted_labels2=logistic_regression.predict(test_data) # prediction of labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "logistic_regression.fit(X,train_labels3)\n",
    "end_time = time.time()\n",
    "training_time=end_time-start_time\n",
    "print(\"Training time for Iris-Verginica: \"+str(training_time))\n",
    "predicted_labels3=logistic_regression.predict(test_data) # prediction of labels for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score - Logistic Regression (library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for Iris-Setosa: \"+str(accuracy_score(test_labels1,predicted_labels1)))\n",
    "print(\"Accuracy for Iris-Versicolour: \"+str(accuracy_score(test_labels2,predicted_labels2)))\n",
    "print(\"Accuracy for Iris-Verginica: \"+str(accuracy_score(test_labels3,predicted_labels3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

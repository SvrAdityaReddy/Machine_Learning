{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'feature_names', 'target', 'target_names', 'DESCR']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.target) #gives a detailed descriptipon of the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(iris['data'])\n",
    "# print(data)\n",
    "data_with_labels=np.insert(data, 0, values=iris['target'], axis=1) # first element is the class label\n",
    "# print(data_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Test and Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set=train_test_split(data_with_labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification (Iris-Virginica or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_set[:,(3,4)] # taking feature petal length and petal width\n",
    "Y=(train_set[:,0]==2).astype(np.int) # to map true and false to 1 and 0 respectively\n",
    "# print(X)\n",
    "# print(Y)\n",
    "test_data=test_set[:,(3,4)] # taking feature petal length and petal width\n",
    "test_labels=(test_set[:,0]==2).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y=(Y==2).astype(np.int) # to map true and false to 1 and 0 respectively\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=[]\n",
    "for i in range(len(test_data)):\n",
    "    # euclidean distance\n",
    "    minimum_distance=((np.dot(test_data[i],test_data[i]))-2*(np.dot(test_data[i],X[0]))+(np.dot(X[0],X[0])))**0.5\n",
    "    closest_neighbour=Y[0]\n",
    "    for j in range(1,len(X)):\n",
    "        # euclidean distance\n",
    "        distance=((np.dot(test_data[i],test_data[i]))-2*(np.dot(test_data[i],X[j]))+(np.dot(X[j],X[j])))**0.5\n",
    "        if(distance < minimum_distance):\n",
    "            minimum_distance=distance\n",
    "            closest_neighbour=Y[j]\n",
    "    predicted_labels.append(closest_neighbour)\n",
    "# print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score - Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data is fitted to a Gaussian\n",
    "def probability(mean, std, x):\n",
    "    exponential=np.exp(-1*(x-mean)**2/(2*(std**2)))\n",
    "    return ((1/(std*((22/7.0)**0.5)))*(exponential))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Gausian\n",
    "def gaussian_parameters(X):\n",
    "    mean=np.mean(X,axis=0)\n",
    "    std=np.std(X,axis=0)\n",
    "    return (mean,std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to get data points corresponding to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class1= [X[i] for i in range(len(Y)) if Y[i]==1] # class1 refers to data corresponding to flower Iris-Virginica\n",
    "data_class2= [X[i] for i in range(len(Y)) if Y[i]==0] # class2 refers to data does not corresponds to flower Iris-Virginica  \n",
    "# print(data_class1)\n",
    "# print(data_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.52051282  2.        ] [ 0.53454005  0.28644595]\n",
      "[ 2.86419753  0.78888889] [ 1.4404482   0.56371782]\n"
     ]
    }
   ],
   "source": [
    "(mean_class1,std_class1)=gaussian_parameters(data_class1) # get each features gaussian parameters if their class is class1\n",
    "(mean_class2,std_class2)=gaussian_parameters(data_class2) # get each features gaussian parameters if their class is class2\n",
    "print(mean_class1,std_class1)\n",
    "print(mean_class2,std_class2)\n",
    "total_class1=0\n",
    "for i in range(len(Y)):\n",
    "    if(Y[i]==1):\n",
    "        total_class1=total_class1+1\n",
    "class1_probability=float(total_class1)/len(Y)\n",
    "class2_probability=1-class1_probability\n",
    "# print(class1_probability)\n",
    "# print(class2_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=[]\n",
    "for i in range(len(test_data)):\n",
    "    probability_class1=1\n",
    "    probability_class2=1\n",
    "    for j in range(len(test_data[i])):\n",
    "        probability_class1=probability_class1*probability(mean_class1[j],std_class1[j],test_data[i][j])\n",
    "        probability_class2=probability_class2*probability(mean_class2[j],std_class2[j],test_data[i][j])\n",
    "    probability_class1=probability_class1*class1_probability\n",
    "    probability_class2=probability_class2*class2_probability\n",
    "#     print(probability_class1,probability_class2)\n",
    "    if(probability_class1>probability_class2):\n",
    "        predicted_labels.append(1)\n",
    "    else:\n",
    "        predicted_labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,predicted_labels)\n",
    "# print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb = GaussianNB()\n",
    "# gnb.fit(X, Y)\n",
    " \n",
    "# # making predictions on the testing set\n",
    "# y_pred = gnb.predict(test_data)\n",
    "# print(y_pred)\n",
    " \n",
    "# # comparing actual response values (y_test) with predicted response values (y_pred)\n",
    "# from sklearn import metrics\n",
    "# print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(test_labels, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of features of test data and insert value \"1\" as first feature in every data point of test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=np.copy(X)\n",
    "X_data=np.insert(X_data, 0, values=[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-1*z))\n",
    "def gradient_descent_logistic_regression(X_data,Y,learning_rate,number_iterations):\n",
    "    theta=np.zeros(X_data.shape[1])\n",
    "    for i in range(number_iterations):\n",
    "        z=np.dot(X_data,theta)\n",
    "        p=sigmoid(z)\n",
    "        gradient=np.dot(X_data.T, (p - Y)) / Y.size\n",
    "#         print(theta)\n",
    "#         print(gradient)\n",
    "        theta=theta-learning_rate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-38.18213454   4.80744687   8.97914439]\n"
     ]
    }
   ],
   "source": [
    "# print(X_data.shape)\n",
    "learning_rate=0.1\n",
    "number_iterations=300000\n",
    "theta=gradient_descent_logistic_regression(X_data,Y,learning_rate,number_iterations)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_new=np.copy(test_data)\n",
    "test_data_new=np.insert(test_data_new, 0, values=[1], axis=1);\n",
    "predicted_labels=[]\n",
    "for i in range(len(test_data_new)):\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta))>0.5):\n",
    "        predicted_labels.append(1)\n",
    "    else:\n",
    "        predicted_labels.append(0)\n",
    "# print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score - Logistic Regression (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_logistic_regression(X_data,Y,number_iterations):\n",
    "    theta=np.zeros(X_data.shape[1])\n",
    "    for i in range(number_iterations):\n",
    "        z=np.dot(X_data,theta)\n",
    "        p=sigmoid(z)\n",
    "        gradient=np.dot(X_data.T, (p - Y)) / Y.size\n",
    "        learning_rate=np.linalg.inv(np.dot(X_data.T,X_data)/ Y.size)\n",
    "#         print(theta)\n",
    "#         print(gradient)\n",
    "        theta=theta-np.dot(learning_rate,gradient)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-41.57478717   5.31187227   9.53893649]\n"
     ]
    }
   ],
   "source": [
    "theta=newton_method_logistic_regression(X_data,Y,number_iterations)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=[]\n",
    "for i in range(len(test_data_new)):\n",
    "    if(sigmoid(np.dot(test_data_new[i],theta))>0.5):\n",
    "        predicted_labels.append(1)\n",
    "    else:\n",
    "        predicted_labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score - Logistic Regression (Newton's method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression=LogisticRegression()\n",
    "logistic_regression.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29438456,  0.70561544]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.predict_proba([[5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=logistic_regression.predict(test_data) # prediction of labels for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score - Logistic Regression (library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
